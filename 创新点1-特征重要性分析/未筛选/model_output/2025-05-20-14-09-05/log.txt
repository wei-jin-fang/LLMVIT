Namespace(batch_size=16, cuda=True, datasetname='data', dropout=0.5, embed='timeF', embed_dim=100, epochs=160, hidden_units=256, log_interval=100, lr=0.001, model_type='LLM_VIT', num_dataset=9, num_heads=5, num_hidden_layers=4, num_layers=2, optim='Adam', print=1, seed=2021)
../../../data/0Train.csv每一类的数量是: [15640, 2160]
../../../data/0Train.csvget_Class函数得到的的权重： [0.5690537084398977, 4.12037037037037]
../../../data/0Val.csv每一类的数量是: [6640, 880]
../../../data/0Val.csvget_Class函数得到的的权重： [0.5662650602409639, 4.2727272727272725]
../../../data/0Test.csv每一类的数量是: [5600, 1400]
../../../data/0Test.csvget_Class函数得到的的权重： [0.625, 2.5]
(17800, 1)
(445,)
(7520, 1)
(188,)
(7000, 1)
(175,)
train_x.shape : (445, 40, 10) 
train_y.shape : (445,) 
validate_x.shape : (188, 40, 10) 
validate_y.shape : (188,) 
test_x.shape : (175, 40, 10) 
test_y.shape : (175,) 
zero: 0.5690537084398977
zero: 4.12037037037037
{0.0: 0.5690537084398977, 1.0: 4.12037037037037}
Namespace(batch_size=16, cuda=True, datasetname='data', dropout=0.5, embed='timeF', embed_dim=80, epochs=200, hidden_units=256, log_interval=100, lr=0.001, model_type='LLM_VIT', num_dataset=9, num_heads=2, num_hidden_layers=4, num_layers=2, optim='Adam', print=0, seed=2021)
====================数据集0测试集轮评估数据=============================================
Processing batch 1
[[[ 5.42128372e-04 -9.34694800e-05  1.48765751e-03 ...  1.16155535e-03
    1.46924788e-03  1.20451747e-03]
  [-4.27072217e-04  7.74868187e-05 -1.92978188e-03 ... -2.11069889e-04
   -2.35256124e-04 -6.76516666e-04]
  [ 9.62578573e-04 -1.62180760e-04  2.47893152e-03 ...  1.56984410e-03
    2.01327891e-03  1.65204591e-03]
  ...
  [-2.29862477e-03  4.05095723e-04 -6.16443764e-03 ... -5.35029369e-03
   -6.72633129e-03 -5.36701073e-03]
  [ 1.31549988e-03 -2.26959572e-04  3.53126673e-03 ...  1.92339322e-03
    2.45327884e-03  2.01615670e-03]
  [-3.83535355e-03  6.64325167e-04 -1.00727991e-02 ... -4.75018258e-03
   -6.01340582e-03 -4.76387593e-03]]

 [[-4.60243368e-04  7.94275920e-05 -1.32291488e-03 ... -1.20869119e-03
   -1.52954664e-03 -1.26939660e-03]
  [ 9.31828651e-04 -1.66279224e-04  3.63721866e-03 ...  8.20065251e-04
    9.90226181e-04  1.51812004e-03]
  [-1.46272041e-03  2.44760438e-04 -3.76029124e-03 ... -2.35877461e-03
   -3.03739815e-03 -2.50879468e-03]
  ...
  [ 2.23980883e-03 -3.92756015e-04  5.97199879e-03 ...  4.96250694e-03
    6.24263559e-03  4.97997762e-03]
  [-1.75709745e-03  3.02791832e-04 -4.75846111e-03 ... -2.53236720e-03
   -3.23777589e-03 -2.68322347e-03]
  [ 3.60474667e-03 -6.24634902e-04  9.45802011e-03 ...  4.57423197e-03
    5.78841064e-03  4.58590211e-03]]]
